{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"nvidia/Llama3-ChatQA-1.5-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map={\"\": 0},\n",
    "        quantization_config=quant_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.2,\n",
    "    return_full_text= False,\n",
    "    do_sample = True,\n",
    "    num_return_sequences=1,\n",
    "    top_k=10,\n",
    "    eos_token_id=terminators,\n",
    ")\n",
    "\n",
    "hf = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RAG Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load From Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "docs = WikipediaLoader(query=\"Candi Borobudur\",lang='id',load_max_docs=2).load()\n",
    "\n",
    "allDocs = \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ")\n",
    "all_splits = text_splitter.split_text(allDocs)\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"firqaaa/indo-sentence-bert-base\")\n",
    "vectorstore = FAISS.from_texts(all_splits, embedding=embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "ret =\"\"\"System: Anda adalah chatbot interaktif yang asik untuk menjawab pertanyaan. Kamu bisa mengambil potongan konteks yang diambil berikut ini untuk menjawab pertanyaan tidak apa untuk bilang tidak tahu. Buatlah jawaban yang ringkas 2 kalimat.\n",
    "\n",
    "          {context}\n",
    "\n",
    "          User: {question}\n",
    "\n",
    "          Assistant:\n",
    "      \"\"\"\n",
    "\n",
    "prompt_retqa = PromptTemplate.from_template(ret)\n",
    "faiss_sim = RetrievalQA.from_chain_type(\n",
    "    llm=hf, chain_type='stuff', return_source_documents=True, chain_type_kwargs={\"prompt\": prompt_retqa},\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "res_sim = faiss_sim('Mengapa Candi Borobudur ditinggalkan?')\n",
    "res_sim['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain, StuffDocumentsChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.memory import ChatMessageHistory, ConversationEntityMemory, ConversationBufferMemory, ConversationSummaryMemory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history.add_ai_message(\"Hai!\")\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2,\n",
    "                                        input_key=\"question\",\n",
    "                                        memory_key=\"chat_history\",\n",
    "                                        chat_memory=history,\n",
    "                                        ai_prefix=\"Assistant\",\n",
    "                                        output_key = \"generated_question\",\n",
    "                                        human_prefix=\"User\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret =\"\"\"System: Anda adalah chatbot interaktif yang asik untuk menjawab pertanyaan. Kamu bisa mengambil potongan konteks yang diambil berikut ini untuk menjawab pertanyaan tidak apa untuk bilang tidak tahu. Buatlah jawaban yang ringkas 2 kalimat.\n",
    "\n",
    "          {context}\n",
    "          {chat_history}\n",
    "          User: {question}\n",
    "\n",
    "          Assistant:\n",
    "\"\"\"\n",
    "prompt_context = PromptTemplate(input_variables=[\"context\", \"chat_history\", \"question\"], template=ret)\n",
    "\n",
    "condense_template =\"\"\"SYSTEM: Gabungkan riwayat obrolan dan pertanyaan lanjutan menjadi pertanyaan mandiri.\n",
    "CHAT_HISTORY : {chat_history}\n",
    "User: {question}\n",
    "Assistant:\n",
    "\"\"\"\n",
    "\n",
    "condense_prompt = PromptTemplate(input_variables=[\"chat_history\", \"question\"], template=condense_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationalRetrievalChain.from_llm(hf,\n",
    "                                              retriever=retriever,\n",
    "                                              memory=memory,\n",
    "                                              condense_question_prompt=condense_prompt,\n",
    "                                              return_generated_question= True,\n",
    "                                              combine_docs_chain_kwargs={'prompt': prompt_context},\n",
    "                                              get_chat_history=lambda h : h, # fix support with memory\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res =  chain(\"Dimana borobudur terletak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_text = res['generated_question'].strip()\n",
    "print(answer_text)\n",
    "# res['answer'].strip()\n",
    "# res[\"generated_question\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis result: [{'label': 'positive', 'score': 0.9756755828857422}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "pretrained_name = \"w11wo/indonesian-roberta-base-sentiment-classifier\"\n",
    "nlp = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=pretrained_name,\n",
    "    tokenizer=pretrained_name\n",
    ")\n",
    "\n",
    "# # Get input from the user\n",
    "# user_input = input(\"Please enter a sentence for sentiment analysis: \")\n",
    "answer_text = \"Memeksaurus\"\n",
    "\n",
    "# Perform sentiment analysis\n",
    "result = nlp(answer_text)\n",
    "\n",
    "# Print the result\n",
    "print(\"Sentiment analysis result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sentiment(result):\n",
    "    return \"Positive\" if result > 0.75 else \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sentiment(result[0]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
